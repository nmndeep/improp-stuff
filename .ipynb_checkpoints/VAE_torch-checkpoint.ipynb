{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=128, shuffle=True)\n",
    "test_iterator = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=128, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def imshow(img):\n",
    "#     img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_iterator)\n",
    "images, labels = dataiter.next()\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128     # number of data points in each batch\n",
    "N_EPOCHS = 10       # times to run the model on complete data\n",
    "INPUT_DIM = 28 * 28 # size of each input\n",
    "HIDDEN_DIM = 256    # hidden dimension\n",
    "LATENT_DIM = 20     # latent vector dimension\n",
    "lr = 1e-3           # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Encoder(nn.Module):\n",
    "    ''' This the encoder part of VAE\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim, z_dim):\n",
    "        '''\n",
    "        Args:\n",
    "            input_dim: A integer indicating the size of input (in case of MNIST 28 * 28).\n",
    "            hidden_dim: A integer indicating the size of hidden dimension.\n",
    "            z_dim: A integer indicating the latent dimension.\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = nn.Linear(input_dim, hidden_dim)\n",
    "        self.mu = nn.Linear(hidden_dim, z_dim)\n",
    "        self.var = nn.Linear(hidden_dim, z_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, input_dim]\n",
    "\n",
    "        hidden = F.relu(self.linear(x))\n",
    "        # hidden is of shape [batch_size, hidden_dim]\n",
    "        z_mu = self.mu(hidden)\n",
    "        # z_mu is of shape [batch_size, latent_dim]\n",
    "        z_var = self.var(hidden)\n",
    "        # z_var is of shape [batch_size, latent_dim]\n",
    "\n",
    "        return z_mu, z_var\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Decoder(nn.Module):\n",
    "    ''' This the decoder part of VAE\n",
    "    '''\n",
    "    def __init__(self, z_dim, hidden_dim, output_dim):\n",
    "        '''\n",
    "        Args:\n",
    "            z_dim: A integer indicating the latent size.\n",
    "            hidden_dim: A integer indicating the size of hidden dimension.\n",
    "            output_dim: A integer indicating the output dimension (in case of MNIST it is 28 * 28)\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = nn.Linear(z_dim, hidden_dim)\n",
    "        self.out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, latent_dim]\n",
    "\n",
    "        hidden = F.relu(self.linear(x))\n",
    "        # hidden is of shape [batch_size, hidden_dim]\n",
    "\n",
    "        predicted = torch.sigmoid(self.out(hidden))\n",
    "        # predicted is of shape [batch_size, output_dim]\n",
    "        return predicted\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, enc, dec):\n",
    "        ''' This the VAE, which takes a encoder and decoder.\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.enc = enc\n",
    "        self.dec = dec\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encode\n",
    "        z_mu, z_var = self.enc(x)\n",
    "\n",
    "        # sample from the distribution having latent parameters z_mu, z_var\n",
    "        # reparameterize\n",
    "        std = torch.exp(z_var / 2)\n",
    "        eps = torch.randn_like(std)\n",
    "        x_sample = eps.mul(std).add_(z_mu)\n",
    "\n",
    "        # decode\n",
    "        predicted = self.dec(x_sample)\n",
    "        return predicted, z_mu, z_var\n",
    "\n",
    "# encoder\n",
    "encoder = Encoder(INPUT_DIM, HIDDEN_DIM, LATENT_DIM)\n",
    "\n",
    "# decoder\n",
    "decoder = Decoder(LATENT_DIM, HIDDEN_DIM, INPUT_DIM)\n",
    "\n",
    "# vae\n",
    "model = VAE(encoder, decoder).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "def train():\n",
    "    # set the train mode\n",
    "    model.train()\n",
    "\n",
    "    # loss of the epoch\n",
    "    train_loss = 0\n",
    "\n",
    "    for i, (x, _) in enumerate(train_iterator):\n",
    "        # reshape the data into [batch_size, 784]\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = x.to(device)\n",
    "\n",
    "        # update the gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        x_sample, z_mu, z_var = model(x)\n",
    "\n",
    "        # reconstruction loss\n",
    "        recon_loss = F.binary_cross_entropy(x_sample, x, size_average=False)\n",
    "\n",
    "        # kl divergence loss\n",
    "        kl_loss = 0.5 * torch.sum(torch.exp(z_var) + z_mu**2 - 1.0 - z_var)\n",
    "\n",
    "        # total loss\n",
    "        loss = recon_loss + kl_loss\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "    return train_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naman/miniconda3/lib/python3.5/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch: 0, Test set: Training loss: -14796.1936, Test loss: -14854.462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    # set the evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # test loss for the data\n",
    "    test_loss = 0\n",
    "\n",
    "    # we don't need to track the gradients, since we are not updating the parameters during evaluation / testing\n",
    "    with torch.no_grad():\n",
    "        for i, (x, _) in enumerate(test_iterator):\n",
    "            # reshape the data\n",
    "            x = x.view(-1, 28 * 28)\n",
    "            x = x.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            x_sample, z_mu, z_var = model(x)\n",
    "\n",
    "            # reconstruction loss\n",
    "            recon_loss = F.binary_cross_entropy(x_sample, x, size_average=False)\n",
    "\n",
    "            # kl divergence loss\n",
    "            kl_loss = 0.5 * torch.sum(torch.exp(z_var) + z_mu**2 - 1.0 - z_var)\n",
    "\n",
    "            # total loss\n",
    "            loss = recon_loss + kl_loss\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    return test_loss\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "\n",
    "for e in range(N_EPOCHS):\n",
    "\n",
    "    train_loss = train()\n",
    "    test_loss = test()\n",
    "\n",
    "    train_loss /= len(train_iterator.dataset)\n",
    "    test_loss /= len(test_iterator.dataset)\n",
    "    \n",
    "    print('\\n Epoch: {}, Training loss: {:.4f}, Test loss: {:.3f}\\n'.format(\n",
    "        e, train_loss, test_loss))\n",
    "\n",
    "    if best_test_loss > test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        patience_counter = 1\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter > 3:\n",
    "        break\n",
    "\n",
    "# sample and generate a image\n",
    "z = torch.randn(1, LATENT_DIM).to(device)\n",
    "reconstructed_img = model.dec(z)\n",
    "img = reconstructed_img.view(28, 28).data\n",
    "\n",
    "print(z.shape)\n",
    "print(img.shape)\n",
    "plt.figure()\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
