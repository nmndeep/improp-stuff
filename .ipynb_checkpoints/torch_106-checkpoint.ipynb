{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision.utils import save_image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "image_size = 784\n",
    "n_dim = 400\n",
    "z_dim = 20\n",
    "bs = 4\n",
    "lr_rate = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torchvision.datasets.MNIST(root = '../datasets/MNIST/',\n",
    "                                    train=True,\n",
    "                                     transform = torchvision.transforms.ToTensor(),\n",
    "                                    download = True)\n",
    "data_loader = torch.utils.data.DataLoader(dataset=data, batch_size=bs, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_size=784, h_dim=400,z_dim=20):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(image_size, h_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc3 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim)\n",
    "        self.fc5 = nn.Linear(h_dim, image_size)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        out = F.relu(self.fc1(x))\n",
    "        return self.fc2(out), self.fc3(out)\n",
    "    \n",
    "    def repara(self, mu, var):\n",
    "        ###    Reparametrization trick to allow for gradients to pass during backprop\n",
    "        st_dev = torch.exp(var/2)\n",
    "        eps = torch.randn_like(st_dev)\n",
    "        return mu + eps * st_dev\n",
    "    \n",
    "    def decode(self, x):\n",
    "        out = F.relu(self.fc4(x))\n",
    "        out = F.sigmoid(self.fc5(out))\n",
    "        return out\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, var = self.encode(x)\n",
    "        z = self.repara(mu, var)\n",
    "        recont = self.decode(z)\n",
    "        return recont, mu, var\n",
    "    \n",
    "model = VAE().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_e = 5\n",
    "for e in range(n_e):\n",
    "    for i, (img, _) in enumerate(data_loader):\n",
    "        \n",
    "        img = img.to(device).view(-1, image_size)\n",
    "        recon, mu, var = model(img)\n",
    "        \n",
    "        #         Loss is the sum of reconstruction loss and kl divergence\n",
    "        \n",
    "        loss_recon = F.binary_cross_entropy(recon, img)\n",
    "        kldiv = 0.5*torch.sum(1 + var - mu.pow(2) - var.exp())\n",
    "        loss_val = loss_recon + kldiv\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if(i+1)%10==0:\n",
    "            print(\"Epoch[{}/{}], step [{}/{}], loss ---recon--->{:.2f}, loss---kl--->{:.2f}\".\n",
    "                 format(e+1, n_e, i+1, len(data_loader), loss_recon.item(), kldiv.item()))\n",
    "    \n",
    "    ####   Test the model\n",
    "    with torch.no_grad():\n",
    "        # Save the sampled images\n",
    "        z = torch.randn(bs, z_dim).to(device)\n",
    "        out = model.decode(z).view(-1, 1, 28, 28)\n",
    "        save_image(out, os.path.join('../datasets/vaesamples/', 'sampled_{}.png'.format(epoch+1)))\n",
    "\n",
    "        # Save the reconstructed images\n",
    "        out, _, _ = model(x)\n",
    "        x_concat = torch.cat([x.view(-1, 1, 28, 28), out.view(-1, 1, 28, 28)], dim=3)\n",
    "        save_image(x_concat, os.path.join('../datasets/vaesamples/', 'reconst_{}.png'.format(epoch+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
